课程：CS307数据库原理
学期：23秋
理论课教师：程然
实验课教师：王维语
实验课时间：星期二1-2节
## 团队基本信息
|成员|学号|百分比|贡献内容|
|-|-|-|-|
|何林翰|12212309|33%|DBMS和文件IO的比较、ER图、报告撰写|
|许致韬|12211818|33%|数据导入的脚本优化|
|董炳闻|12211111|33%|数据导入、数据库设计|
## 任务1：E-R图
我们使用[draw.io](https://draw.io)绘制E-R图，如下。
![[E-R图.png]]

## 任务2：数据库设计
（数据库图表）
（简要描述表格和列的设计，包括但不限于表格和列的含义）
## 任务3：数据导入
我们编写、改进了……脚本来导入文件，文件附后
我们的脚本使用Bufferreader类导入数据，使用了……
以下是实体表中的记录数。

|user|video|comment|
|-|-|-|
|37881|7865|12478996|
我们尝试了以下导入数据的方法：
1. 1
2. 
## 任务4：比较DBMS与文件I/O
### 4.1 实验环境
#### 4.1.1 硬件规格
- **设备名称**：RedmiBook Pro 14 锐龙版
- **处理器**：AMD Ryzen 7 5700U with Radeon Graphics 1.80 GHz
- **机带RAM**：16.0 GB (15.3 GB 可用)
- **系统类型**：64 位操作系统, 基于 x64 的处理器
#### 4.1.2 软件规格
- **DBMS版本**：PostgreSQL 14.9
- **操作系统**：Windows 10 家庭中文版，版本号：22H2
- **WSL版本**： Ubuntu 22.04.2 LTS (GNU/Linux 5.15.90.1-microsoft-standard-WSL2 x86_64)
- **sysbench版本**：sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)
##### 编程语言：Java
- **版本号**："19.0.1" 2022-10-18
- **IDE版本**：lntelliJ IDEA 2022.3.2
- **依赖的库及其版本**：==todo==
### 4.2 实验设计
#### 4.2.1 实验目的
1. 比较数据库 API 和文件 API 之间的数据检索和操作性能，对增删改查的语句/操作的运行时间进行比较研究。
2. 验证我们设计的数据库是否能处理高并发。
3. （如可能）比较不同的数据库软件（例如 MySQL、MariaDB、SQLite）、文件系统、磁盘性能和类型、编程语言、库或操作系统的性能。
#### 4.2.2 实验计划
我们计划进行如下实验：  
- **实验1**： 对比不同规模的插入、删除、更新操作在Java、PostgreSQL中的效率，规模从1000次到10000、100000次。
- **实验2**： 对比相同的查询语句在Java、PostgreSQL的效率，包括单表的数量查询、排序查询以及多表的联合查询。
- **实验3**：使用sysbench，对比MySQL和PostgreSQL的效率。
- **实验4**：使用pgbench，探究高并发环境下不同并发对PostgreSQL的TPS影响。
### 4.3 对比不同规模的插入、删除、更新操作在JavaIO、PostgreSQL中的效率
#### 4.3.1 测试数据：
`users.csv`文件中的记录数目较小，测试的意义有限，因此，在`DataGenerator.java`中，我们创建了一个CSV格式的测试数据文件，包含了1000000行和7列不同类型的数据。为确保数据的多样性和真实性，我们对每一列进行了详细的定制和随机生成。
1. **mid (长整型)**：范围在1到2^32之间的1000000个唯一的长整型数字。
2. **name (字符串)**：长度限制在16以内的，随机选择`BILIBILI_NAME`和中英文随机字符拼接。
3. **sex (字符串)**：在`{"男", "女", "保密"}`中随机选择一个值。
4. **birthday (字符串)**：年份在1920到2023之间。注意到`users.csv`表中有约80%的空值，我们设置了20%的概率生成生日数据。
5. **level (整型)**：在0到6之间随机生成。
6. **sign (字符串)**：长度在1-255随机的中英文混合随机文本。
7. **identity (字符串)**：在`{"user", "superuser"}`中，以10%的概率选择"superuser"，其余选择"user"。
最终的CSV文件包括一个标题行和1000000个数据行，每行都有7个字段，对应于不同类型的测试数据。通过这种方式，我们生成了一个结构清晰、格式统一、内容丰富的测试数据集，以便进行进一步的数据分析和处理。
#### 4.3.2 测试脚本：
导入的脚本使用了[[#任务3：数据导入|数据导入]]模块的文件
#### 4.3.3 测试结果：

#### 4.3.4 结果分析：

### 4.4 对比相同的查询语句在Java、PostgreSQL的效率
#### 4.4.1 测试数据：
我们使用了提供的`users.csv`和`likes.csv`
#### 4.4.2 测试脚本：

#### 4.4.3 测试结果：

#### 4.4.4 结果分析：

### 4.5 对比MySQL和PostgreSQL的效率
在此实验中，我们使用了[[sysbench](https://github.com/akopytov/sysbench)]，一款基于 LuaJIT 的可编写脚本，最常用于数据库基准测试的多线程基准测试工具。
#### 4.5.1 测试数据：
我们使用sysbench自带的prepare功能生成了测试数据。
#### 4.5.2 测试脚本：
我们使用了sysbench自带的脚本进行性能测试。以下是不同类型的OLTP基准测试，它们主要关注在高并发环境下各自的性能表现：
1. 只读测试
2. 读写测试
3. 插入测试
4. 删除测试
5. 索引更新测试
6. 非索引更新测试
#### 4.5.3 测试结果：
#### 4.5.4 结果分析：
### 4.6 探究高并发环境下并发数对PostgreSQL的效率影响
#### 4.6.1 测试数据：
#### 4.6.2 测试脚本：
#### 4.6.3 测试结果：
#### 4.6.4 结果分析：
##### 实验4：
我们使用了pgbench生成的数据集，其较为简单，其中主表`pgbunch_accounts`仅有自增主键列和仅包含1、仅包含0的列。

#### 4.2.3 测试SQL语句

## 总结
