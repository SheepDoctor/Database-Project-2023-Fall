- 课程：CS307数据库原理
- 学期：23秋
- 理论课教师：程然
- 实验课教师：王维语
- 实验课时间：星期二1-2节
## 团队基本信息
|成员|学号|百分比|贡献内容|
|-|-|-|-|
|何林翰|12212309|33%|DBMS和文件IO的比较、ER图、报告撰写|
|许致韬|12211818|33%|数据导入的脚本优化、报告撰写|
|董炳闻|12211111|33%|数据导入、数据库设计、报告撰写|
## 任务1：E-R图
我们使用[draw.io](https://draw.io)绘制E-R图，如下。
![[er.png]]

## 任务2：数据库设计
### 2.1 数据库图表可视化
![[tables.png]]
### 2.1 表格属性含义
#### 2.1.1 实体表
实体表包含users, videos，具体介绍如下：
1. users：包含用户的基本信息（包含是否为reviewer的信息），由用户的mid作为主键。表格中属性包含name（昵称）、sex（性别）、birthday（生日）、level（等级）、sign（签名）、identity（身份——会员、非会员）和 is_reviewer（是否为审查员）。
2. videos：包含视频的基本信息，由视频的bv作为主键。表中属性包含title（标题）、owern_id（发布者id）、commit_time（提交时间）、public_time（发布时间）、duration（时长）和description（视频简介）。
#### 2.1.2 关系表
关系表包括follow, review, favourites, coins, likes, view, comment，具体介绍如下：
1. follow：记录关注关系，由关注、被关注用户的mid作为联合主键。
2. review：记录审核关系，由视频的bv以及审核员的mid作为联合主键。表中的review_time记录视频审核的时间。
3. favourites：记录收藏关系，由视频的bv以及用户的mid作为联合主键。
4. coins：记录投币关系，由视频的bv以及用户的mid作为联合主键。
5. likes：记录点赞关系，由视频的bv以及用户的mid作为联合主键。
6. view：记录观看关系，由视频的bv以及用户的mid作为联合主键。表中的time记录用户观看视频的时间。
7. comment：包含弹幕信息，由于一个用户可以同时在一个视频中发出多条弹幕，故引入一个id作为主键。表中属性包含bv（视频的id）、mid（发布弹幕的用户的id）、time（发布弹幕的时间）、content（弹幕的内容）。

#### 2.2 外键设计
数据库中有3个实体表，6个关表，其中关系表follow的两个外键均依赖于users表，其余的关系表均依赖于videos表和users表。实体表中的comment表格（弹幕信息）的外键也依赖于videos和users表格。
#### 2.3 重要的约束
1. 对视频的bv的格式做了相关约束
2. 设置时间等数据非空
3. 为性别等数据设置了默认值
## 任务3：数据导入
### 3.1 基础脚本 
#### 3.1.1 语言以及依赖
我们编写Java脚本来导入文件，文件附后。
我们的脚本依赖外部包Bufferreader以及opencsv类导入数据。
#### 3.1.2 数据记录
实体表中的记录数：

|user|video|
|-|-|
|37881|7865|

关系表中的记录数：

|view|follow|coins|likes|favourites|review|comment|
|-|-|-|-|-|-|-|
|163997974|5958770|80571520|86757948|79181895|7865|12478996|

#### 3.1.3 导入方法
1. 数据预处理：对于弹幕数据，由于弹幕中会出现英文逗号(",")和转移字符，故经常导致opencsv分词错误。因此，我们需要进行数据预处理。首先将数据分隔符用正则表达式搜索出来，替换成'\7'，一个不会被用户输入的安全分隔符。与此同时，在数据中搜索转义字符‘\’，将所有的转义字符替换成非转移字符串"\_reversed"，在录入数据的时候进行还原操作即可。
2. 运用Object类进行数据泛化，将数据的类型抹去，保留其数值，用用户自定义类型规范解读标准，从而增强导入脚本的泛化能力，对于不同的表格，仅需更改文件路径、数据类型参数表即可。
3. 对于含有多数据的内容，我们将数据拆分，并且与不变量进行配对，进行数据导入。
4. 脚本采用预编译SQL语句，并且使用BATCH = 10000进行数据导入，预编译使数据库中的执行计划已经被优化和缓存，同时，使用BATCH导入减少了客户端与数据库之间的通信次数、降低了事务的提交和回滚的次数、有效地利用数据库引擎的优化和缓存机制，优化脚本导入速度，提高了脚本性能
#### 导入用时
opencsv脚本导入用时438s左右。
### 3.2 优化脚本
为了减少运行时间，我们采用了CachedThreadPool线程池来加快数据处理速度。鉴于脚本呈现出快读取慢写入的特点，我们在PreparedStatement中累计一定数据时开启一个线程进行写入操作，同时从文件中读取数据。这种方法使得导入时间缩短了六分之一到二分之一不等。在优化脚本的过程中，我们多次修改控制导入数据的规模，以求达到效率最高的同时避免导入数据的遗失。
### 3.3  其他导入数据方法
#### 3.3.1 基于BufferReader的导入方法
我们针对弹幕表，尝试了bufferreader的导入方法，其大致步骤与opencsv类似，如下：
1. 数据预处理：将文件中作为分隔符的英文逗号替换成'\7'，将弹幕内容中的所有'\n'换成"/_ reversedn"，保留每条记录的换行符
2. 运用Object类保存数据，并且将数据泛化，同上
3. 在最后导入数据的时候，将转移字符替换成正常的转移字符，储存到PretreatStatement
4. 用batch提交，最后commit
与opencsv方法比较，此方法用了538s，多出100s的导入时间，效果不如使用opencsv导入数据。
#### 3.3.2 基于面向过程的导入方法

我们针对users、danmu表中存在的换行和特殊字符类型，使用了面向过程的导入方法，并未使用opencsv库，其步骤如下：
1. 使用bufferreader从目标文件中读取一行，针对数据存储格式中的逗号、单引号、双引号、中括号等出现的位置以及数量进行初步判断
2. 如果其格式符合目标数据格式，则读入，否则再读入一行，直到整体数据符合目标格式
3. 因为在判断数据格式的同时对数据进行了一定处理，故而只需将数据按顺序放入PreparedStatement中即可
4. 用batch提交，与opencsv方法相比较，此方法并未使用外部库，对运行环境要求较低，使用的内存空间较少，运行时数据冗余量少。
## 任务4：比较DBMS与文件I/O
### 4.1 实验环境
#### 4.1.1 硬件规格
- **设备名称**：RedmiBook Pro 14 锐龙版
- **处理器**：AMD Ryzen 7 5700U with Radeon Graphics 1.80 GHz
- **机带RAM**：16.0 GB (15.3 GB 可用)
- **系统类型**：64 位操作系统, 基于 x64 的处理器
#### 4.1.2 软件规格
- **DBMS版本**：PostgreSQL 14.9
- **操作系统**：Windows 10 家庭中文版，版本号：22H2
- **WSL版本**： Ubuntu 22.04.2 LTS (GNU/Linux 5.15.90.1-microsoft-standard-WSL2 x86_64)
- **sysbench版本**：sysbench 1.0.20 (using system LuaJIT 2.1.0-beta3)
##### 编程语言：Java
- **版本号**："19.0.1" 2022-10-18
- **IDE版本**：lntelliJ IDEA 2022.3.2
- **依赖的库及其版本**：==todo== 
### 4.2 实验设计
#### 4.2.1 实验目的
1. 比较数据库 API 和文件 API 之间的数据检索和操作性能，对增删改查的语句/操作的运行时间进行比较研究。
2. 验证我们设计的数据库是否能处理高并发。
3. （如可能）比较不同的数据库软件（例如 MySQL、MariaDB、SQLite）、文件系统、磁盘性能和类型、编程语言、库或操作系统的性能。
#### 4.2.2 实验计划
我们计划进行如下实验：  
- **实验1**： 对比不同规模的插入、删除、更新操作在Java、PostgreSQL中的效率，规模从1000次到10000、100000次不等。
- **实验2**： 对比相同的查询语句在Java、PostgreSQL的效率，包括单表的数量查询、排序查询以及多表的联合查询。
- **实验3**：使用sysbench，对比MySQL和PostgreSQL的效率。
- **实验4**：使用sysbench，探究并发数对PostgreSQL的TPS影响。
### 4.3 对比不同规模的插入、删除、更新操作在JavaIO、PostgreSQL中的效率
Java自带的文件IO和PostgreSQL在效率、功能上有哪些差异？这是我们实验关心的主要问题。
#### 4.3.1 测试数据：
`users.csv`文件中的记录数目较小，测试的意义有限，因此，在`DataGenerator.java`中，我们创建了一个CSV格式的测试数据文件，包含了1000000行和7列不同类型的数据。为确保数据的多样性和真实性，我们对每一列进行了详细的定制和随机生成。
1. **mid (长整型)**：范围在1到2^32之间的1000000个唯一数字。
2. **name (字符串)**：长度限制在16以内的，随机选择`BILIBILI_NAME`和中英文随机字符拼接。
3. **sex (字符串)**：在`{"男", "女", "保密"}`中随机选择一个值。
4. **birthday (字符串)**：年份在1920到2023之间。注意到`users.csv`表中有约80%的空值，我们设置了20%的概率生成生日数据。
5. **level (整型)**：在0到6之间随机生成。
6. **sign (字符串)**：长度在1-255随机的中英文混合随机文本。
7. **identity (字符串)**：在`{"user", "superuser"}`中，以10%的概率选择"superuser"，其余选择"user"。
最终的CSV文件包括一个标题行和1000000个数据行，每行都有7个字段，对应于不同类型的测试数据。通过这种方式，我们生成了一个结构清晰、格式统一、内容丰富的测试数据集，以便进行进一步的数据分析和处理。
#### 4.3.2 测试脚本：
- **插入**：随机选择一定数量的行，将其移除后，记录将这些行插入回去所需时间。
- **删除**：在文件IO中，将删除后的文件存为新文件。记录随机删除一定数量的行所需时间。
- **更新**：随机选取sign中一定数量的空值，将其更新为“该用户太懒了，没有留下任何介绍哦。”

| |插入|删除|更新|
|-|-|-|-|
|文件IO|`InsertWithJavaIO.java`|`DeletetWithJavaIO.java`|`UpdatetWithJavaIO.java`|
|DBMS|`InsertWithDBMS.java`|`DeletetWithDBMS.java`|`UpdatetWithDBMS.java`|
|预处理|`RandomCSVDeletion.java`|无|无|
#### 4.3.3 测试结果：

![[Pasted image 20231110212340.png]]
在许多基准测试中，初始阶段并不具有代表性，因为 CPU、数据库、页面和其他缓存需要一些时间来预热。因此，我们连续运行7或15次指定脚本，并且去掉前1/3的结果。
#### 4.3.4 结果分析：
在对结果的分析中，我们发现几个有趣的点：
1. **随着记录数的增加，插入速度也在增加，但增速小于记录数的增长**。这可能是因为：
	 - **批处理和优化：** 当插入的记录数增加时，DBMS 可能在内部进行更有效的批处理和查询优化。
	 - **缓存和预热：** 随着操作的进行，数据库的缓存机制可能变得更加高效，特别是在重复访问相同的数据页面时。
	 - **非线性开销：** 数据库在处理插入操作时涉及额外的开销，如索引维护、事务日志记录等，这些开销不一定与记录数成正比增长。
2. **文件 I/O 的插入速度远高于 DBMS**。这可能是因为：
	- 文件系统操作通常更直接、更少开销。没有额外的处理如索引维护、ACID（原子性、一致性、隔离性、持久性）事务保证等。
	- 笔者能力有限，写作的脚本优化程度还可以更高。
1. **在 DBMS 中，删除和更新操作的速度通常低于插入**。这可能是因为：
	- **数据定位**： 删除和更新操作需要首先定位到特定的记录，这可能涉及查找或全表扫描。
	- **附加操作：** 更新操作可能涉及额外的步骤，如检查数据约束、更新索引、写入事务日志等。
2.  **对于文件 I/O，删除和更新操作的效率也低于插入**。这可能是因为：
	- **文件定位和重写：** 在文件系统中，删除和更新可能需要首先读取整个文件（或大部分文件）以定位特定记录，然后进行修改和重写，这比单纯的追加写入（插入）要慢。
	- **数据覆盖和移动：** 更新操作可能需要覆盖旧数据或在文件中移动数据，这比简单的顺序写入更耗时。
##### 结论
总的来说，这些实验结果揭示了 DBMS 和文件I/O在处理不同数据库操作时的性能特点：DBMS提供了更复杂的功能和保障，如数据完整性、并发控制等，但这些功能通常以牺牲一定的性能为代价；而文件I/O在处理某些操作时可能更快，但它缺乏DBMS提供的许多高级特性和保护。
### 4.4 对比相同的查询语句在Java、PostgreSQL的效率
#### 4.4.1 测试数据：
我们使用了提供的`users.csv`和`likes.csv`
#### 4.4.2 测试脚本：

#### 4.4.3 测试结果：

#### 4.4.4 结果分析：

### 4.5 对比MySQL和PostgreSQL的效率
在此实验中，我们使用了[sysbench](https://github.com/akopytov/sysbench)，一款基于 LuaJIT 的可编写脚本的，常用于数据库基准测试的，多线程基准测试工具。
鉴于sysbench只能在Linux操作系统上运行，我们还下载了Windows Subsystem for Linux (WSL) 中的 Ubuntu 22.04.2 版本，并在其上运行sysbench。
#### 4.5.1 测试数据：
我们使用sysbench自带的prepare功能生成了测试数据。
通过观察可以发现，该测试数据的第一列为自增主键，第二列为索引列，第三、四列是用`-`分隔开的较大数字。
#### 4.5.2 测试脚本：
我们使用了sysbench自带的脚本进行性能测试。以下是不同类型的OLTP基准测试，它们主要关注在高并发环境下各自的性能表现：
1. **只读**测试 `oltp_read_only.lua`
2. **读写**测试 `oltp_read_write.lua`
3. **插入**测试 `oltp_insert.lua`
4. **删除**测试 `oltp_delete.lua`
5. **索引更新**测试 `oltp_update_index.lua`
6. **非索引更新**测试 `oltp_update_non_index.lua`
7. **随机选择数据点**测试 `select_random_points.lua`
8. **随机选择数据范围**测试 `select_random_ranges.lua`
#### 4.5.3 测试结果：
##### **预实验**：
在初步的测试中，我们发现，在相同线程下，PostgreSQL的速度显著快于MySQL，但是MySQL能承担的线程数大于PostgreSQL。因此，为了使得两个DBMS都在最适合的线程数下运行，我们使用读写测试脚本，进行了线程数不同、时间较短的预实验，得到的数据如下。

|线程数|1|2|4|8|16|32|64|96|112|120|128|136|144|150|
|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|
|MySQL的TPS|56|85|108|139|183|238|326|506|509|553|574|408|356|默认最大|

|线程数|1|2|4|8|16|32|48|56|64|96|100|
|-|-|-|-|-|-|-|-|-|-|-|-|
|PostgreSQL的TPS|73|134|234|387|801|1225|1150|1459|1400|1266|默认最大|
经过分析，我们发现在给定条件（读写脚本，16个表格，100w数据，10秒）下，最适合PostgreSQL和MySQL的线程数分别**可能**是56，120。另外，由于10秒的时间太短，可能有较多的随机因素干扰，所以这里的实验求出的最适合线程数并不一定准确。
##### 正式实验：
我们进行200秒的较长时间测试，以求排除随机因素的影响。对于有显著暖机时间的操作，我们去除了前20秒的预热部分。表中单位：TPS(transaction per second)

|DBMS\\测试类型|只读|读写|插入|删除|索引更新|非索引更新|随机选择数据点|随机选择数据范围|
|-|-|-|-|-|-|-|-|-|
|MySQL|2678|460|2228|1430|1789|2055|36967|47489|
|PostgreSQL|1738|1016|4444|15582|4340|6403|35040|11932|

#### 4.5.4 结果分析：
在对结果的分析中，我们发现几个有趣的点：
##### 1. 查询、更新操作的性能稳定性
选择操作、更新操作的效率随时间变化很小，非常稳定，波动程度显著小于读写操作的效率随时间的变化程度，而且没有所谓的暖机时间，一开始就达到了平均值。可能的原因如下：
- **缓存效应：** 数据库通常会将频繁访问的数据缓存在内存中。对于选择（查询）和更新操作，如果工作集（即频繁操作的数据集）较小，它可能很快就完全被缓存起来，从而导致性能非常稳定。
- **预编译的语句：** 因为使用的是预编译的查询，数据库可以快速地执行这些操作，因为它不需要重复解析和计划这些查询。
- **操作简单性：** 简单的查询和更新操作可能不会对数据库系统造成太大压力，从而导致性能表现比较稳定。
##### 2. 读写操作的暖机时间和性能波动
读写操作有暖机时间，效率小于查询，且效率在某些时段急剧减小。可能的原因如下：
- **暖机时间：** 读写操作（特别是写操作）在开始时可能需要一定的“暖机”时间。在这个暖机阶段，数据库可能在建立必要的缓存、调整内部结构（如 B-Tree 的平衡），或者进行其他初始化操作。
- **资源竞争和I/O开销：** 读写操作可能导致更频繁的磁盘I/O，特别是在处理大量数据时。磁盘I/O是数据库操作中最慢的部分，会显著影响性能。
- **锁和并发控制：** 读写操作可能涉及更复杂的锁定机制和并发控制。在高并发环境中，多个事务同时读取和修改数据可能导致锁争用，进而影响性能。
- **数据库内部的自动调整：** 数据库系统可能会根据当前的工作负载自动调整其内部参数（如缓存大小、查询计划等）。在长时间的测试中，这种调整可能导致性能的波动。
##### 3.不同DBMS在不同操作的性能差异
在其余条件均相同的情况下，PostgreSQL在更新，读写的方面都好于MySQL，唯独在查询方面落后。可能的原因如下：
- **索引策略差异：** PostgreSQL 和 MySQL 在索引实现和优化策略上存在差异。PostgreSQL 提供更多的索引类型并且在某些情况下可能更有效，尤其是在复杂查询中。然而，对于sysbench自带的简单查询，MySQL 可能由于其相对简单的优化器和索引策略而更快。
- **默认配置：** PostgreSQL 和 MySQL 的默认配置差异可能导致性能表现不同。例如，内存分配、缓存大小和查询优化参数可能在两个系统中有所不同。
- **数据组织：** 即使是相同的数据，由于两个数据库系统在存储和组织数据方面的差异，比如不同的数据引擎或数据架构，相同的操作可能在 PostgreSQL 和 MySQL 上表现不同。
### 结论
这些现象反映了数据库系统在处理不同类型操作时的内部机制差异。缓存、查询优化、I/O开销、锁机制等都可能对性能产生显著影响。理解这些因素可以帮助我们对数据库性能进行优化，以及合适地选择我们需要的DBMS。
### 4.6 探究并发数对PostgreSQL的效率影响
在先前的实验4.5中，我们发现，在线程数不高的情况下，效率会随着线程数的增加而上升，但是到一定范围后上升减缓甚至停止，**为了更精确地探究高并发数对DMBS的影响**，我们进行此测试。测试工具与实验4.5相同，使用sysbench，尽管该工具没有模拟多客户端的功能，但是可以使用多线程来模拟多客户端的高并发现象。
#### 4.6.1 测试数据：
测试数据与实验4.5相同，使用sysbench的prepare功能生成的数据。
#### 4.6.2 测试脚本：
1. **读写**测试 `oltp_read_write.lua`
2. **随机选择数据点**测试 `select_random_points.lua`
#### 4.6.3 测试结果：
我们进行了40次实验，每组时长100s，结果如下。每组单位为TPS(transaction per second)

|线程数|5|10|15|20|25|30|35|40|45|50|55|60|65|70|75|80|85|90|95|100|
|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|
|读写|-|-|-|-|-|793|-|-|-|1|1197|1|-|-|-|1187|1374|1426|1451|1486|
|选择|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|
#### 4.6.4 结果分析：

## 总结
